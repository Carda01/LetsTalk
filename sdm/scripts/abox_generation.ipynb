{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d82a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import names\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sys.path.append(os.path.abspath(\"../../\")) \n",
    "\n",
    "# Standard libraries\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "# Your project modules\n",
    "from dags.lib.pt_utils import *\n",
    "from dags.lib.IncrementalLoader import IncrementalLoader\n",
    "from dags.lib.Processer import *\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from delta import *\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0ce44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, when\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "def extract_column_keywords(df, text_columns=['content', 'title', 'description'], top_n=10):\n",
    "    \"\"\"\n",
    "    Returns: List of top keywords (without frequencies)\n",
    "    \"\"\"\n",
    "    combined_df = df.withColumn(\n",
    "        \"combined_text\",\n",
    "        concat_ws(\" \", *[\n",
    "            when(col(c).isNotNull(), col(c)).otherwise(\"\")\n",
    "            for c in text_columns\n",
    "        ]))\n",
    "    \n",
    "    texts = [row.combined_text for row in combined_df.select(\"combined_text\").collect()]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        scores = X[i].toarray().flatten()\n",
    "        top_indices = scores.argsort()[-3:][::-1]\n",
    "        keywords.extend(feature_names[top_indices])\n",
    "    \n",
    "    # Return just the words as a list\n",
    "    return [word for word, count in Counter(keywords).most_common(top_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f339eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "DBO = Namespace(\"http://sdm_upc.org/ontology/\")\n",
    "DBR = Namespace(\"http://sdm_upc.org/resource/\")\n",
    "\n",
    "\n",
    "g.bind(\"dbo\", DBO)\n",
    "g.bind(\"dbr\", DBR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820a44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_hash(value):\n",
    "    return int(hashlib.sha256(str(value).encode()).hexdigest(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3ffd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc8ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dags.lib.pt_utils:False\n",
      "INFO:dags.lib.pt_utils:False\n"
     ]
    }
   ],
   "source": [
    "is_gcs_enabled= \"False\"\n",
    "if is_gcs_enabled.lower() == 'true':\n",
    "    is_gcs_enabled = True\n",
    "else:\n",
    "    is_gcs_enabled = False\n",
    "\n",
    "spark, base_path = get_spark_and_path(is_gcs_enabled)\n",
    "\n",
    "trusted_path ='..\\..\\data\\letstalk_trusted_zone_bdma'\n",
    "\n",
    "#SPORTS\n",
    "## Matches\n",
    "\n",
    "subpath = 'matches'\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    if row.status_long in ('match finished', 'walkover', 'technical loss', 'match abandoned'):\n",
    "        subject = URIRef(DBR + f\"match_{row.fixture_id}\")\n",
    "\n",
    "        if row.team_home_id is not None:\n",
    "            g.add((subject, DBO.match_home_team, URIRef(DBR + f\"team_{row.team_home_id}\")))\n",
    "\n",
    "        if row.team_away_id is not None:\n",
    "            g.add((subject, DBO.match_away_team, URIRef(DBR + f\"team_{row.team_away_id}\")))\n",
    "\n",
    "        if row.goals_home is not None:\n",
    "            g.add((subject, DBO.match_home_goals, Literal(int(row.goals_home), datatype=XSD.integer)))\n",
    "            \n",
    "        if row.goals_away is not None:\n",
    "            g.add((subject, DBO.match_away_goals, Literal(int(row.goals_away), datatype=XSD.integer)))\n",
    "\n",
    "        if row.fixture_date is not None:\n",
    "            g.add((subject, DBO.match_date, Literal(row.fixture_date, datatype=XSD.dateTime)))\n",
    "\n",
    "        if row.status_long is not None:\n",
    "            g.add((subject, DBO.match_played, Literal(str(row.status_long), datatype=XSD.string)))\n",
    "\n",
    "        if row.league is not None:\n",
    "            g.add((subject, DBO.match_competition, URIRef(DBR + f\"competition_{row.league}\")))\n",
    "\n",
    "        if row.referee is not None:\n",
    "            g.add((subject, DBO.match_referee, URIRef(DBR + f\"referee_{consistent_hash(row.referee)}\")))\n",
    "            g.add((URIRef(DBR + f\"referee_{consistent_hash(row.referee)}\"), DBO.referee_name, Literal(str(row.referee), datatype=XSD.string)))\n",
    "\n",
    "        if row.venue_id is not None:\n",
    "            g.add((subject, DBO.match_venue, URIRef(DBR + f\"venue_{consistent_hash(row.venue_id)}\")))\n",
    "\n",
    "\n",
    "## Competitions\n",
    "\n",
    "subpath= 'leagues'\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "league_ids = df.select(\"league_id\").distinct().rdd.map(lambda row: row.league_id).collect()\n",
    "country_ids = df.select(\"country\").distinct().rdd.map(\n",
    "    lambda row: row.country.code\n",
    ").filter(lambda code: code is not None).collect()\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR + f\"competition_{row.league_id}\")\n",
    "    if row.league_type == 'cup':\n",
    "        g.add((subject, RDF.type, DBO.Cup))\n",
    "    else:\n",
    "        g.add((subject, RDF.type, DBO.League))\n",
    "    \n",
    "    if row.league_name is not None:\n",
    "        g.add((subject, DBO.competition_name,Literal(str(row.league_name), datatype=XSD.string)))\n",
    "\n",
    "    if row.country is not None:\n",
    "        if row.country.name== 'World':\n",
    "            g.add((subject, DBO.competition_country, URIRef(DBR + f\"country_{consistent_hash('world')}\")))\n",
    "            g.add((URIRef(DBR + f\"country_{consistent_hash('world')}\"), DBO.country_name, Literal(str(row.country.name), datatype=XSD.string)))\n",
    "        else:\n",
    "            g.add((subject, DBO.competition_country, URIRef(DBR + f\"country_{consistent_hash(row.country.code)}\")))\n",
    "            g.add((URIRef(DBR + f\"country_{consistent_hash(row.country.code)}\"), DBO.country_name, Literal(str(row.country.name), datatype=XSD.string)))\n",
    "        \n",
    "            \n",
    "## Teams\n",
    "subpath= 'teams'\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "team_ids = df.select(\"team_id\").distinct().rdd.map(lambda row: row.team_id).collect()\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR + f\"team_{row.team_id}\")\n",
    "    if row.team_name is not None:\n",
    "        g.add((subject, DBO.team_name, Literal(str(row.team_name), datatype=XSD.string)))\n",
    "        \n",
    "## Venues\n",
    "subpath= 'venues'\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR + f\"venue_{consistent_hash(row.venue_id)}\")\n",
    "    if row.venue_name is not None:\n",
    "        g.add((subject, DBO.venue_name, Literal(str(row.venue_name), datatype=XSD.string)))\n",
    "    if row.venue_city is not None:\n",
    "        g.add((subject, DBO.venue_city, Literal(str(row.venue_city), datatype=XSD.string)))\n",
    "\n",
    "#ENTERTAINMENT\n",
    "##Movies\n",
    "\n",
    "subpath= 'movie'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "film_ids = df.select(\"film_id\").distinct().rdd.map(lambda row: row.film_id).collect()\n",
    "for row in df.toLocalIterator():\n",
    "\n",
    "    subject = URIRef(DBR+f\"film_{row.film_id}\")\n",
    "    \n",
    "    if row.title is not None:\n",
    "        g.add((subject, DBO.movie_title, Literal(str(row.title), datatype=XSD.string )))\n",
    "    if row.original_title is not None:\n",
    "        g.add((subject, DBO.movie_language, Literal(str(row.original_title), datatype=XSD.string )))\n",
    "    if row.release_date is not None:\n",
    "        g.add((subject, DBO.movie_release_date, Literal(row.release_date, datatype=XSD.date )))\n",
    "    if row.revenue is not None:\n",
    "        g.add((subject, DBO.movie_revenue, Literal(int(row.revenue), datatype=XSD.integer)))\n",
    "    if row.budget is not None:\n",
    "        g.add((subject, DBO.movie_budget, Literal(int(row.budget), datatype=XSD.integer )))\n",
    "    runtime_value = row.runtime\n",
    "    if runtime_value is not None and not math.isnan(runtime_value):\n",
    "        g.add((subject, DBO.movie_runtime, Literal(int(runtime_value), datatype=XSD.integer)))\n",
    "    if row.adult is not None:\n",
    "        g.add((subject, DBO.movie_adult, Literal(bool(row.adult), datatype=XSD.boolean)))\n",
    "    if row.popularity is not None:\n",
    "        g.add((subject, DBO.movie_popularity, Literal(float(row.popularity), datatype=XSD.long)))\n",
    "    if row.vote_average is not None:\n",
    "        g.add((subject, DBO.movie_vote_avg, Literal(float(row.vote_average), datatype=XSD.long)))\n",
    "    if row.vote_count is not None:\n",
    "        g.add((subject, DBO.movie_vote_cnt, Literal(int(row.vote_count), datatype=XSD.integer)))\n",
    "\n",
    "subpath= 'movie_genre'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"film_{row.film_id}\")\n",
    "    object = URIRef(DBR+f\"genre_{row.genre_id}\")\n",
    "    g.add((subject, DBO.has_genre, object))\n",
    "\n",
    "subpath= 'trending'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"film_{row.film_id}\")\n",
    "    g.add((subject, DBO.trending_movie, Literal(bool(True), datatype=XSD.boolean)))\n",
    "  \n",
    "subpath= 'upcoming'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"film_{row.film_id}\")\n",
    "    g.add((subject, DBO.upcoming_movie, Literal(bool(True), datatype=XSD.boolean)))\n",
    "\n",
    "subpath= 'now_playing'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"film_{row.film_id}\")\n",
    "    g.add((subject, DBO.now_playing_movie, Literal(bool(True), datatype=XSD.boolean)))\n",
    "    \n",
    "## Genres\n",
    "subpath= 'genre'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "genre_ids = df.select(\"genre_id\").distinct().rdd.map(lambda row: row.genre_id).collect()\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"genre_{row.genre_id}\")\n",
    "    g.add((subject, DBO.genre_name, Literal(str(row.genre), datatype=XSD.string )))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#NEWS\n",
    "kws=[]\n",
    "\n",
    "subpath= 'entertainment'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "kw= extract_column_keywords(df,top_n= 15)\n",
    "kws.append(kw)\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"news_{consistent_hash(row.url)}\")\n",
    "    g.add((subject, RDF.type, DBO.Entertainment_News))\n",
    "    if row.author is not None:\n",
    "        g.add((subject, DBO.written_by, URIRef(DBR+f\"author_{consistent_hash(row.author)}\")))\n",
    "        g.add((URIRef(DBR+f\"author_{consistent_hash(row.author)}\"), DBO.author_name, Literal(str(row.author), datatype=XSD.string )))\n",
    "    if row.source is not None:\n",
    "        g.add((subject, DBO.published_at,  URIRef(DBR+f\"source_{consistent_hash(row.source)}\")))\n",
    "        g.add((URIRef(DBR+f\"source_{consistent_hash(row.source)}\"), DBO.source_name, Literal(str(row.source), datatype=XSD.string )))\n",
    "    if row.title is not None:\n",
    "        g.add((subject, DBO.news_title, Literal(str(row.title), datatype=XSD.string )))\n",
    "    if row.publishedAt is not None:\n",
    "        g.add((subject, DBO.news_date, Literal(row.publishedAt, datatype=XSD.dateTime)))\n",
    "    \n",
    "    text_fields = [\n",
    "        (row.title or \"\").lower(),\n",
    "        (row.content or \"\").lower(),\n",
    "        (row.description or \"\").lower()\n",
    "    ]\n",
    "\n",
    "    for keyword in kw:\n",
    "        keyword_lower = keyword.lower()\n",
    "        if any(keyword_lower in field for field in text_fields):\n",
    "            g.add((subject, DBO.related_keyword, URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\")))\n",
    "            g.add((URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\"),DBO.keyword_text, Literal(str(keyword), datatype=XSD.string )))\n",
    "\n",
    "subpath= 'sports'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "kw= extract_column_keywords(df,top_n= 15)\n",
    "kws.append(kw)\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"news_{consistent_hash(row.url)}\")\n",
    "    g.add((subject, RDF.type, DBO.Sports_News))\n",
    "    if row.author is not None:\n",
    "        g.add((subject, DBO.written_by, URIRef(DBR+f\"author_{consistent_hash(row.author)}\")))\n",
    "        g.add((URIRef(DBR+f\"author_{consistent_hash(row.author)}\"), DBO.author_name, Literal(str(row.author), datatype=XSD.string )))\n",
    "    if row.source is not None:\n",
    "        g.add((subject, DBO.published_at,  URIRef(DBR+f\"source_{consistent_hash(row.source)}\")))\n",
    "        g.add((URIRef(DBR+f\"source_{consistent_hash(row.source)}\"), DBO.source_name, Literal(str(row.source), datatype=XSD.string )))\n",
    "    if row.title is not None:\n",
    "        g.add((subject, DBO.news_title, Literal(str(row.title), datatype=XSD.string )))\n",
    "    if row.publishedAt is not None:\n",
    "        g.add((subject, DBO.news_date, Literal(row.publishedAt, datatype=XSD.dateTime)))\n",
    "    \n",
    "    text_fields = [\n",
    "        (row.title or \"\").lower(),\n",
    "        (row.content or \"\").lower(),\n",
    "        (row.description or \"\").lower()\n",
    "    ]\n",
    "\n",
    "    for keyword in kw:\n",
    "        keyword_lower = keyword.lower()\n",
    "        if any(keyword_lower in field for field in text_fields):\n",
    "            g.add((subject, DBO.related_keyword, URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\")))\n",
    "            g.add((URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\"),DBO.keyword_text, Literal(str(keyword), datatype=XSD.string )))\n",
    "\n",
    "subpath= 'technology'\n",
    "\n",
    "path = os.path.join(trusted_path, subpath)\n",
    "df = DeltaTable.forPath(spark, path).toDF()\n",
    "kw= extract_column_keywords(df,top_n= 15)\n",
    "kws.append(kw)\n",
    "for row in df.toLocalIterator():\n",
    "    subject = URIRef(DBR+f\"news_{consistent_hash(row.url)}\")\n",
    "    g.add((subject, RDF.type, DBO.Tech_News))\n",
    "    if row.author is not None:\n",
    "        g.add((subject, DBO.written_by, URIRef(DBR+f\"author_{consistent_hash(row.author)}\")))\n",
    "        g.add((URIRef(DBR+f\"author_{consistent_hash(row.author)}\"), DBO.author_name, Literal(str(row.author), datatype=XSD.string )))\n",
    "    if row.source is not None:\n",
    "        g.add((subject, DBO.published_at,  URIRef(DBR+f\"source_{consistent_hash(row.source)}\")))\n",
    "        g.add((URIRef(DBR+f\"source_{consistent_hash(row.source)}\"), DBO.source_name, Literal(str(row.source), datatype=XSD.string )))\n",
    "    if row.title is not None:\n",
    "        g.add((subject, DBO.news_title, Literal(str(row.title), datatype=XSD.string )))\n",
    "    if row.publishedAt is not None:\n",
    "        g.add((subject, DBO.news_date, Literal(row.publishedAt, datatype=XSD.dateTime)))\n",
    "    \n",
    "    text_fields = [\n",
    "        (row.title or \"\").lower(),\n",
    "        (row.content or \"\").lower(),\n",
    "        (row.description or \"\").lower()\n",
    "    ]\n",
    "\n",
    "    for keyword in kw:\n",
    "        keyword_lower = keyword.lower()\n",
    "        if any(keyword_lower in field for field in text_fields):\n",
    "            g.add((subject, DBO.related_keyword, URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\")))\n",
    "            g.add((URIRef(DBR + f\"keyword_{consistent_hash(keyword)}\"),DBO.keyword_text, Literal(str(keyword), datatype=XSD.string )))\n",
    "\n",
    "\n",
    "#USERS\n",
    "for i in range(USERS):\n",
    "    subject = URIRef(DBR+f\"user_{i}\")\n",
    "    g.add((subject, DBO.user_name, Literal(str(names.get_full_name()), datatype=XSD.string )))\n",
    "    g.add((subject, DBO.user_country, URIRef(DBR+f\"country_{consistent_hash(random.choice(country_ids))}\")))\n",
    "     # Likes movies\n",
    "    liked_films = random.sample(film_ids, min(len(film_ids), random.randint(0, 3)))\n",
    "    for film_id in liked_films:\n",
    "        g.add((subject, DBO.likes_movie, URIRef(DBR + f\"film_{film_id}\")))\n",
    "\n",
    "    # Likes genres\n",
    "    liked_genres = random.sample(genre_ids, min(len(genre_ids), random.randint(0, 3)))\n",
    "    for genre_id in liked_genres:\n",
    "        g.add((subject, DBO.likes_genre, URIRef(DBR + f\"genre_{genre_id}\")))\n",
    "\n",
    "    # Likes teams\n",
    "    liked_teams = random.sample(team_ids, min(len(team_ids), random.randint(0, 3)))\n",
    "    for team_id in liked_teams:\n",
    "        g.add((subject, DBO.likes_team, URIRef(DBR + f\"team_{team_id}\")))\n",
    "\n",
    "    # Likes competitions\n",
    "    liked_competitions = random.sample(league_ids, min(len(league_ids), random.randint(0, 3)))\n",
    "    for comp_id in liked_competitions:\n",
    "        g.add((subject, DBO.likes_competition, URIRef(DBR + f\"competititon_{comp_id}\")))\n",
    "\n",
    "    # Interested in keywords\n",
    "    interested_keywords = random.sample(kws, min(len(kws), random.randint(0, 5)))\n",
    "    for kw in interested_keywords:\n",
    "        g.add((subject, DBO.interested_in, URIRef(DBR + f\"keyword_{consistent_hash(kw)}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53911a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N13effb02abe741dab4f1295d79ecfe47 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(\"../docker-import/abox.ttl\", format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
