{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82963bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:lib.pt_utils:False\n",
      "INFO:lib.pt_utils:False\n",
      "Delta table does not exist. Starting initialization\n",
      "INFO:dags.lib.pt_utils:CDF not available — doing full load\n",
      "INFO:dags.lib.pt_utils:CDF not available — doing full load\n",
      "INFO:dags.lib.pt_utils:CDF not available — doing full load\n",
      "INFO:dags.lib.pt_utils:Removed 0 simple duplicate(s)\n",
      "INFO:dags.lib.pt_utils:Removed 0 hidden duplicate(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif spark.catalog.tableExists(\"my_database.my_table\")\\n\\nCATEGORIES = [\\'entertainment\\', \\'sports\\', \\'technology\\']\\nfor category in CATEGORIES:\\n    logging.info(f\"Processing category {category}\")\\n    table_subpath = f\\'delta_news/{category}\\'\\n    loader = IncrementalLoader(spark, landing_path, table_subpath, is_gcs_enabled)\\n    df = loader.get_new_data()\\n\\n    processor = NewsProcessor(spark, df, is_gcs_enabled)\\n\\n    logging.info(processor.df.show(3))\\n    logging.info(f\"Processing {processor.df.count()} elements\")\\n    processor.ensure_schema()\\n    processor.remove_clear_duplicates()\\n    processor.name_to_id()\\n    processor.remove_hidden_duplicates([\\'url\\'], [\\'publishedAt\\'])\\n    processor.normalize_text([\\'title\\', \\'description\\', \\'content\\'])\\n    processor.expand_source()\\n    processor.order_by(\\'publishedAt\\', ascending=False)\\n\\n    logging.info(\"End processing\")\\n    logging.info(processor.df.show(3))\\n\\n    save_path = os.path.join(trusted_path, table_subpath)\\n    processor.merge_with_trusted(trusted_path, table_subpath, [\\'url\\'])\\n    loader.update_control_table()\\n\\n\\nspark.stop()\\nlogging.info(\"Data was merged\")\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from lib.pt_utils import *\n",
    "from lib.IncrementalLoader import IncrementalLoader\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from delta import *\n",
    "from lib.Processer import *\n",
    "\n",
    "#is_gcs_enabled = os.getenv('IS_GCS_ENABLED')\n",
    "is_gcs_enabled= \"False\"\n",
    "if is_gcs_enabled.lower() == 'true':\n",
    "    is_gcs_enabled = True\n",
    "else:\n",
    "    is_gcs_enabled = False\n",
    "\n",
    "spark, base_path = get_spark_and_path(is_gcs_enabled)\n",
    "\n",
    "landing_path = '..\\data\\letstalk_landing_zone_bdma' #get_landing_path(base_path)\n",
    "trusted_path ='..\\data\\letstalk_trusted_zone_bdma'\n",
    "\n",
    "path= '..\\data\\letstalk_trusted_zone_bdma\\control_table'\n",
    "\n",
    "try:\n",
    "    delta_table = DeltaTable.forPath(spark, path)\n",
    "    print(\"Delta table exists.\")\n",
    "except AnalysisException:\n",
    "    print(\"Delta table does not exist. Starting initialization\")\n",
    "    movies_subpath = r'delta_tmdb\\database\\movie'\n",
    "    genre_subpath  = r'delta_tmdb\\database\\genre'\n",
    "    movies_genre_subpath = r'delta_tmdb\\database\\movie_genre'\n",
    "\n",
    "    loader = IncrementalLoader(spark, landing_path, movies_subpath)\n",
    "    df = loader.get_new_data()\n",
    "    loader_genre = IncrementalLoader(spark, landing_path, genre_subpath)\n",
    "    df_genre= loader_genre.get_new_data()\n",
    "    loader_mov_gen = IncrementalLoader(spark, landing_path, movies_genre_subpath)\n",
    "    df_mov_gen= loader_mov_gen.get_new_data()\n",
    "\n",
    "    processor = TMDBProcessor(spark, df)\n",
    "\n",
    "    processor.ensure_schema()\n",
    "    processor.normalize_text(['overview'])\n",
    "    processor.remove_clear_duplicates()\n",
    "    processor.remove_hidden_duplicates(['film_id'], ['ingestion_time'], True)\n",
    "\n",
    "    processor.set_genre_df(df_genre)\n",
    "    processor.ensure_schema_genres()\n",
    "\n",
    "    processor.genre_df = processor.genre_df.withColumn(\"genre\", lower(col(\"genre\")))\n",
    "    processor.genre_df = processor.genre_df.withColumn(\"genre\", regexp_replace(col(\"genre\"), r\"http\\S+|www\\.\\S+\", \" \"))\n",
    "    processor.genre_df = processor.genre_df.withColumn(\"genre\", regexp_replace(col(\"genre\"), r\"[^a-zA-Z\\s]\", \" \"))\n",
    "    processor.genre_df.dropDuplicates()\n",
    "    window = Window.partitionBy(*[\"genre\"]).orderBy(*[\"genre_id\"])\n",
    "    processor.genre_df= (\n",
    "            processor.genre_df.withColumn(\"row_num\", F.row_number().over(window)).filter(F.col(\"row_num\") == 1).drop(\"row_num\")\n",
    "            )\n",
    "\n",
    "    processor.set_movie_genre_df(df_mov_gen)\n",
    "    processor.ensure_schema_movie_genres()\n",
    "    processor.movie_genre_df.dropDuplicates()\n",
    "\n",
    "    processor.static_dump(trusted_path)\n",
    "\"\"\"\n",
    "if spark.catalog.tableExists(\"my_database.my_table\")\n",
    "\n",
    "CATEGORIES = ['entertainment', 'sports', 'technology']\n",
    "for category in CATEGORIES:\n",
    "    logging.info(f\"Processing category {category}\")\n",
    "    table_subpath = f'delta_news/{category}'\n",
    "    loader = IncrementalLoader(spark, landing_path, table_subpath, is_gcs_enabled)\n",
    "    df = loader.get_new_data()\n",
    "\n",
    "    processor = NewsProcessor(spark, df, is_gcs_enabled)\n",
    "\n",
    "    logging.info(processor.df.show(3))\n",
    "    logging.info(f\"Processing {processor.df.count()} elements\")\n",
    "    processor.ensure_schema()\n",
    "    processor.remove_clear_duplicates()\n",
    "    processor.name_to_id()\n",
    "    processor.remove_hidden_duplicates(['url'], ['publishedAt'])\n",
    "    processor.normalize_text(['title', 'description', 'content'])\n",
    "    processor.expand_source()\n",
    "    processor.order_by('publishedAt', ascending=False)\n",
    "\n",
    "    logging.info(\"End processing\")\n",
    "    logging.info(processor.df.show(3))\n",
    "\n",
    "    save_path = os.path.join(trusted_path, table_subpath)\n",
    "    processor.merge_with_trusted(trusted_path, table_subpath, ['url'])\n",
    "    loader.update_control_table()\n",
    "\n",
    "\n",
    "spark.stop()\n",
    "logging.info(\"Data was merged\")\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
